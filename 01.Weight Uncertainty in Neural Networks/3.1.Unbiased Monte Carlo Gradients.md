**1. Objective Function (Variational Free Energy)**

The goal is to minimize the variational free energy, $F(D, \theta)$, which is defined as:
$$ F(D, \theta) = \text{KL}[q(w|\theta) || P(w)] - \mathbb{E}_{q(w|\theta)}[\log P(D|w)] $$

This can be expanded using the definition of KL divergence:
$$ \text{KL}[q(w|\theta) || P(w)] = \int q(w|\theta) \log \frac{q(w|\theta)}{P(w)} dw = \mathbb{E}_{q(w|\theta)}[\log q(w|\theta) - \log P(w)] $$

Substituting this back, we get:
$$ F(D, \theta) = \mathbb{E}_{q(w|\theta)}[\log q(w|\theta) - \log P(w)] - \mathbb{E}_{q(w|\theta)}[\log P(D|w)] $$

Combining the expectations:
$$ F(D, \theta) = \mathbb{E}_{q(w|\theta)}[\log q(w|\theta) - \log P(w) - \log P(D|w)] $$

Let's define the term inside the expectation as $f(w, \theta)$:
$$ f(w, \theta) = \log q(w|\theta) - \log P(w) - \log P(D|w) $$

So the objective function is:
$$ F(D, \theta) = \mathbb{E}_{q(w|\theta)}[f(w, \theta)] = \int f(w, \theta) q(w|\theta) dw $$

**2. Gradient Calculation**

We need to compute the gradient of $F(D, \theta)$ with respect to the variational parameters $\theta$:
$$ \nabla_\theta F(D, \theta) = \nabla_\theta \mathbb{E}_{q(w|\theta)}[f(w, \theta)] = \nabla_\theta \int f(w, \theta) q(w|\theta) dw $$

The main difficulty is that the distribution $q(w|\theta)$ depends on $\theta$.

**3. Reparameterization Trick (Proposition 1)**

The core idea is to reparameterize the random variable $w$.

*   **Assumption 1:** There exists a base random variable $\epsilon$ with a fixed probability density $q(\epsilon)$ that *does not* depend on $\theta$. (e.g., $\epsilon \sim \mathcal{N}(0, I)$).
*   **Assumption 2:** There exists a deterministic and differentiable transformation $t$ such that $w = t(\theta, \epsilon)$. Sampling $\epsilon \sim q(\epsilon)$ and applying $w = t(\theta, \epsilon)$ is equivalent to sampling $w \sim q(w|\theta)$.
*   **Condition:** This implies a change of variables relationship, often written as $q(w|\theta) dw = q(\epsilon) d\epsilon$.

Under these assumptions, the expectation can be rewritten over the fixed distribution $q(\epsilon)$:
$$ F(D, \theta) = \mathbb{E}_{q(\epsilon)}[f(t(\theta, \epsilon), \theta)] = \int f(t(\theta, \epsilon), \theta) q(\epsilon) d\epsilon $$

Now, we can compute the gradient by moving the operator inside the integral, as $q(\epsilon)$ is independent of $\theta$:
$$ \nabla_\theta F(D, \theta) = \nabla_\theta \mathbb{E}_{q(\epsilon)}[f(t(\theta, \epsilon), \theta)] = \mathbb{E}_{q(\epsilon)}[\nabla_\theta f(t(\theta, \epsilon), \theta)] $$

Applying the chain rule to the term inside the expectation (where $f$ depends on $\theta$ both directly and indirectly via $w=t(\theta, \epsilon)$):
$$ \nabla_\theta f(t(\theta, \epsilon), \theta) = [\nabla_\theta t(\theta, \epsilon)]^\top [\nabla_w f(w, \theta)]|_{w=t(\theta, \epsilon)} + [\nabla_\theta f(w, \theta)]|_{w=t(\theta, \epsilon)} $$

Here:
*   $\nabla_\theta t(\theta, \epsilon)$ is the Jacobian of $t$ with respect to $\theta$.
*   $\nabla_w f(w, \theta)$ is the gradient of $f$ with respect to its first argument $w$.
*   $\nabla_\theta f(w, \theta)$ is the gradient of $f$ with respect to its second argument $\theta$.
*   $|_{w=t(\theta, \epsilon)}$ indicates evaluation at $w = t(\theta, \epsilon)$.

The paper uses a slightly less formal partial derivative notation, directly giving the result stated in Proposition 1 (assuming $\theta$ could be scalar or applying element-wise):
$$ \frac{\partial}{\partial\theta} \mathbb{E}_{q(w|\theta)} [f(w, \theta)] = \mathbb{E}_{q(\epsilon)} \left[ \frac{\partial f}{\partial w} \frac{\partial w}{\partial \theta} + \frac{\partial f}{\partial \theta} \right] $$
where $w = t(\theta, \epsilon)$, $\frac{\partial w}{\partial \theta} = \frac{\partial t(\theta, \epsilon)}{\partial \theta}$, and the partial derivatives of $f$ are evaluated at $(t(\theta, \epsilon), \theta)$.

**4. Monte Carlo Estimation**

The gradient, now expressed as an expectation over the fixed distribution $q(\epsilon)$, can be estimated using Monte Carlo sampling:

1.  Draw $M$ samples $\epsilon^{(1)}, \epsilon^{(2)}, \dots, \epsilon^{(M)}$ independently from $q(\epsilon)$.
2.  For each sample $i$:
    *   Compute $w^{(i)} = t(\theta, \epsilon^{(i)})$.
    *   Compute the gradient sample $g^{(i)}$:
        $$ g^{(i)}(\theta) = \left[ \frac{\partial f}{\partial w} \frac{\partial t}{\partial \theta} + \frac{\partial f}{\partial \theta} \right]_{w=w^{(i)}, \epsilon=\epsilon^{(i)}, \theta} $$
        (using the slightly informal notation)
        Or more formally:
        $$ g^{(i)}(\theta) = [\nabla_\theta t(\theta, \epsilon^{(i)})]^\top [\nabla_w f(w, \theta)]|_{w=w^{(i)}} + [\nabla_\theta f(w, \theta)]|_{w=w^{(i)}} $$
3.  Estimate the gradient as the sample average:
    $$ \nabla_\theta F(D, \theta) \approx \hat{g} = \frac{1}{M} \sum_{i=1}^{M} g^{(i)}(\theta) $$

This provides an unbiased estimate of the true gradient $\nabla_\theta F(D, \theta)$.